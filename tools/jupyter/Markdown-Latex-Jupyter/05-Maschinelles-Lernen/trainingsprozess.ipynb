{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ee628ca6",
      "metadata": {},
      "source": [
        "# Training von Entscheidungsbäumen\n",
        "Im letzten Kapitel wurden alle Daten für das Training des Entscheidungsbaums verwendet. Getestet wurde im Anschluss mit den selben Daten. Ob der Baum für andere Daten gute Ergebnisse liefert, wurde nicht überprüft.\n",
        "In diesem Kapitel sollen die eingelesenen Daten (möglichst zufällig) in **drei Gruppen** aufgeteilt werden:\n",
        "- **Trainingsdaten**: Mit diesen Datensätzen soll der Baum berechnet werden.\n",
        "- **Validierungsdaten**: Mit diesen Datensätzen soll geprüft werden, ob der Baum gut funktioniert. Wenn sich hierbei herausstellt, dass das Modell noch nicht gut genug ist, dann werden die so genannten *Hyperparamter* (s.u.) abgeändert und der Trainigsprozess wird erneut durchgeführt.\n",
        "- **Testdaten**: Mit diesen Daten wird der Anwendungsfall simuliert. Dieser findet erst **nach** der Trainingsphase statt, wenn die KI fertig ist und eingesetzt werden soll. \n",
        "\n",
        "Anhand der Testdaten wird abschließend entschieden, ob das Modell für den vorgesehenen Einsatzzweck akzeptiert wird. Die Testdaten werden also niemals während des iterativen Trainings des Modells verwendet. Auf diese Weise soll ein so genanntes *Overfitting* des Modells an die Trainigs- und Validierungddaten erkannt und vermieden werden.\n",
        "\n",
        "Eine Aufteilung in diese 3 Gruppen macht nur Sinn, wenn viele Daten vorhanden sind. Deshalb werden hier immer alle 55 Lebensmittel (**d55.csv**) verwendet."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81210778",
      "metadata": {},
      "source": [
        "<center>\n",
        "<img width=\"60%\" src=\"trainingsprozess.png\"/>\n",
        "<center>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b37373c0",
      "metadata": {},
      "source": [
        "## Einlesen der Daten und erster Überblick"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a05f2473",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "daten = pd.read_csv('d55.csv')\n",
        "display(daten.head(5))   # Anzeige der ersten n Datensätze"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15c345b3",
      "metadata": {},
      "source": [
        "## Aufteilung der Daten in zufällige Gruppen\n",
        "Im folgenden Quelltext kann man die **Größe der einzelnen Gruppen angeben**. Die Summe muss dabei natürlich der Anzahl der Datensätze entsprechen. \n",
        "\n",
        "Oft wird für die Aufteilungverhältnis der Trainigs-, Validierungs und Testdaten von 70% : 15% : 15% gewählt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87c6d08e",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "anzahl_training    = 35\n",
        "anzahl_validierung = 15\n",
        "anzahl_test        = len(daten) - anzahl_training - anzahl_validierung   # der Rest\n",
        "print( \"Aufteilungsverhältnis:\", \n",
        "       round(anzahl_training/len(daten)*100,1) ,\"% :\",\n",
        "       round(anzahl_validierung/len(daten)*100,1) ,\"% :\",\n",
        "       round(anzahl_test/len(daten)*100,1) ,\"%\" )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31e5f472-452d-43aa-a098-2a8d0147027b",
      "metadata": {},
      "source": [
        "Für die zufällige Verteilung auf die drei Gruppen erzeugen wir eine **Zufallsliste** mit den Nummern der Datensätze, in der die Elemente mit **random.shuffle** durchgemischt werden.\n",
        "Du kannst diesen Block mehrmals ausführen und dabei das wiederholte Neumischen in der Ausgabe beobachten."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da5eda24",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import random\n",
        "zufallsliste= list( range(len(daten)) ) # Liste mit den Nummern von 0 bis Anzahl der Datensätze\n",
        "random.shuffle( zufallsliste )          # Liste wird zufällig durchgeschüttelt\n",
        "print( zufallsliste )                   # Ausgabe zur Kontrolle"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45b8d097-269b-43a8-a40f-182e549c31bc",
      "metadata": {},
      "source": [
        "Jetzt müssen noch die **Daten in die einzelnen Gruppen** aufgeteilt werden. Dazu verwenden wir natürlich die Zufallsliste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4469e7ce",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "daten_training    = daten.loc[ zufallsliste[:anzahl_training] ] \n",
        "daten_validierung = daten.loc[ zufallsliste[anzahl_training:anzahl_training+anzahl_validierung] ] \n",
        "daten_test        = daten.loc[ zufallsliste[anzahl_training+anzahl_validierung:] ]\n",
        "#print(daten_training['Name'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a68f545",
      "metadata": {},
      "source": [
        "## Training des Entscheidungsbaums\n",
        "Wie im vorigen Kapitel können jetzt die **Parameter der Berechnung** und der Darstellung angepasst werden."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21fc4910",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import sklearn.tree\n",
        "import matplotlib\n",
        "\n",
        "attribute = ['Eiweiss','Salz']\n",
        "baumtiefe = 2\n",
        "\n",
        "baum = sklearn.tree.DecisionTreeClassifier(max_depth=baumtiefe)\n",
        "baum.fit( daten_training[attribute], daten_training['Label'] )\n",
        "sklearn.tree.plot_tree( baum, feature_names=attribute, label=\"none\", \n",
        "                        filled=True,\n",
        "                        class_names=[\"ungesund\",\"gesund\"], impurity=False,\n",
        "                        proportion=False, fontsize=8 )\n",
        "matplotlib.pyplot.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b72a721",
      "metadata": {},
      "source": [
        "## Validierung\n",
        "Die Validierung wird nun mit den **Validierungsdaten** durchgeführt. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcfeb93e",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def validierung(datenliste):\n",
        "  korrekt = 0\n",
        "  falsch = 0\n",
        "  for datensatz in datenliste.index:  #Schleife über alle Validierungs-Datensätze\n",
        "      if( baum.predict(datenliste.loc[[datensatz]][attribute]) == (datenliste.loc[datensatz]['Label']) ):  \n",
        "           korrekt += 1\n",
        "      else:\n",
        "          falsch += 1\n",
        "          print(\"Fehler bei\", datenliste.loc[datensatz]['Name'])\n",
        "  gesamt = korrekt + falsch\n",
        "  print( \"Anzahl falsch klassifiziert: \",  falsch, \"(\" , round(falsch/gesamt*100,2), \"% )\")  \n",
        "  print( \"Anzahl korrekt klassifiziert: \", korrekt, \"(\" , round(korrekt/gesamt*100,2), \"% )\") \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49330ca5",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"**************  V A L I D I E R U N G  *************\")\n",
        "validierung(daten_validierung)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e2072bd",
      "metadata": {},
      "source": [
        "<div style=\"padding: 5px; border: 5px solid #0077b6;\">\n",
        "\n",
        "### Aufgabe 1: Iterative Verbesserung des Modells\n",
        "Gehe nun zurück zum Abschnitt [Training des Entscheidungsbaums](##Training-des-Entscheidungsbaums) und verändere die so genannten *Hyperparameter*\n",
        "- atrribute\n",
        "- baumtiefe\n",
        "- Aufteilungsverhältnis der Daten in Traings-, Validierung- und Testdaten\n",
        "\n",
        "solange, bis du zufrieden bist mit dem Ergebnis."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc94a278",
      "metadata": {},
      "source": [
        "---\n",
        "# Akzeptanz-Test\n",
        "Erst **nach** dem vollständigen Abschluss des iterativen Trainigsprozesses wird nur die Akzeptanzkontrolle mittels der **Testdaten** durchgeführt. Beachte, dass die Testdaten nun völlig neu für unser Modell sind, da wir diese im Trainingsprozess niemals verwendet haben."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d90094a",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"**************      T E S T U N G      *************\")\n",
        "validierung(daten_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da204f98",
      "metadata": {},
      "source": [
        "Wenn das Erbebnis zufriedenstellend ist, dann wird das nun fertig trainierte und getestete Modell im produktiven Einsatz verwedendet.\n",
        "\n",
        "Andernfalls wird es verworfen und es wird ein anderes Modell entworfen."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c727ab60",
      "metadata": {},
      "source": [
        "<div style=\"padding: 5px; border: 5px solid #0077b6;\">\n",
        "\n",
        "### Aufgabe 2: Beurteile dein fertiges Modell\n",
        "Beurteile dein fertiges Modell. Falls du nicht zufrieden damit bist, dann äußere Vermutungen darüber, was schief gegangen sein könnte."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecc988bc",
      "metadata": {},
      "source": [
        "Ergebnisse bitte hierher"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e00eb11c",
      "metadata": {},
      "source": [
        "---\n",
        "# Aufbereitung der Daten"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09f35bc8",
      "metadata": {},
      "source": [
        "<div style=\"padding: 5px; border: 5px solid #0077b6;\">\n",
        "\n",
        "### Aufgabe 3: Aufbereitung der Daten\n",
        "Arbeite die folgende Seite über den Prozess der [Aufbereitung der Daten](https://mlu-explain.github.io/train-test-validation/) durch. Halte schriftlich fest, welche Aspekte dort zusätzlich erwähnt werden, die wir in diesem Notebook aber bisher überhaupt nicht berücksichtigt haben.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "535610a3",
      "metadata": {},
      "source": [
        "Ergebnisse bitte hier festhalten"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b924084a",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}